{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation using BERTscore\n",
    "\n",
    "[Source](https://huggingface.co/spaces/evaluate-metric/bertscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>biases_detected</th>\n",
       "      <th>scores</th>\n",
       "      <th>output_agent</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estimada comunidad beauchefiana: ¿Tienes papel...</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desde hoy y hasta el 19 de diciembre puedes de...</td>\n",
       "      <td>GENERIC_PRONOUNS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Desde hoy y hasta el 19 de diciembre puedes de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revisa en el afiche qué tipo de papeles puedes...</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>¡Les esperamos!</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Estimada Comunidad:   La Subdirección de Puebl...</td>\n",
       "      <td>EXCLUSIONARY_TERMS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Estimada Comunidad:   La Subdirección de Puebl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input     biases_detected  \\\n",
       "0  Estimada comunidad beauchefiana: ¿Tienes papel...            UNBIASED   \n",
       "1  Desde hoy y hasta el 19 de diciembre puedes de...    GENERIC_PRONOUNS   \n",
       "2  Revisa en el afiche qué tipo de papeles puedes...            UNBIASED   \n",
       "3                                    ¡Les esperamos!            UNBIASED   \n",
       "4  Estimada Comunidad:   La Subdirección de Puebl...  EXCLUSIONARY_TERMS   \n",
       "\n",
       "  scores                                       output_agent  index  \n",
       "0    1.0                                           UNBIASED      0  \n",
       "1    0.8  Desde hoy y hasta el 19 de diciembre puedes de...      1  \n",
       "2    1.0                                           UNBIASED      2  \n",
       "3    1.0                                           UNBIASED      3  \n",
       "4    0.8  Estimada Comunidad:   La Subdirección de Puebl...      4  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../agent/predictions.csv\")\n",
    "df = df.drop(columns=['debias_reasoning'])\n",
    "df = df.rename(columns={\"biases\": \"biases_detected\",\"output\":\"output_agent\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['output'] = df.apply(lambda row: row['input'] if row['biases_detected'] == 'UNBIASED' else row['output_agent'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "819"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['biases_detected'] = df['biases_detected'].fillna('UNBIASED')\n",
    "df['output'] = df['output'].fillna('UNBIASED')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748\n"
     ]
    }
   ],
   "source": [
    "df_causal = pd.read_csv(\"../../data/processed/20231220_metrics_CAUSAL.csv\")\n",
    "df = pd.merge(df, df_causal[['input','sesgo_pronombre','sesgo_otro','target']], on='input', how='inner')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>biases_detected</th>\n",
       "      <th>scores</th>\n",
       "      <th>output_agent</th>\n",
       "      <th>index</th>\n",
       "      <th>output</th>\n",
       "      <th>sesgo_pronombre</th>\n",
       "      <th>sesgo_otro</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estimada comunidad beauchefiana: ¿Tienes papel...</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>0</td>\n",
       "      <td>Estimada comunidad beauchefiana: ¿Tienes papel...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>['Estimada comunidad beauchefiana: ¿Tienes pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desde hoy y hasta el 19 de diciembre puedes de...</td>\n",
       "      <td>GENERIC_PRONOUNS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Desde hoy y hasta el 19 de diciembre puedes de...</td>\n",
       "      <td>1</td>\n",
       "      <td>Desde hoy y hasta el 19 de diciembre puedes de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Desde hoy y hasta el 19 de diciembre puedes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Revisa en el afiche qué tipo de papeles puedes...</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>2</td>\n",
       "      <td>Revisa en el afiche qué tipo de papeles puedes...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Revisa en el afiche qué tipo de papeles pued...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estimada Comunidad:   La Subdirección de Puebl...</td>\n",
       "      <td>EXCLUSIONARY_TERMS</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Estimada Comunidad:   La Subdirección de Puebl...</td>\n",
       "      <td>4</td>\n",
       "      <td>Estimada Comunidad:   La Subdirección de Puebl...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>['Estimada Comunidad:   La Subdirección de Pue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Postulaciones, labores y más información en:  ...</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNBIASED</td>\n",
       "      <td>5</td>\n",
       "      <td>Postulaciones, labores y más información en:  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Postulaciones, labores y más información en:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input     biases_detected  \\\n",
       "0  Estimada comunidad beauchefiana: ¿Tienes papel...            UNBIASED   \n",
       "1  Desde hoy y hasta el 19 de diciembre puedes de...    GENERIC_PRONOUNS   \n",
       "2  Revisa en el afiche qué tipo de papeles puedes...            UNBIASED   \n",
       "3  Estimada Comunidad:   La Subdirección de Puebl...  EXCLUSIONARY_TERMS   \n",
       "4  Postulaciones, labores y más información en:  ...            UNBIASED   \n",
       "\n",
       "  scores                                       output_agent  index  \\\n",
       "0    1.0                                           UNBIASED      0   \n",
       "1    0.8  Desde hoy y hasta el 19 de diciembre puedes de...      1   \n",
       "2    1.0                                           UNBIASED      2   \n",
       "3    0.8  Estimada Comunidad:   La Subdirección de Puebl...      4   \n",
       "4    1.0                                           UNBIASED      5   \n",
       "\n",
       "                                              output sesgo_pronombre  \\\n",
       "0  Estimada comunidad beauchefiana: ¿Tienes papel...              NO   \n",
       "1  Desde hoy y hasta el 19 de diciembre puedes de...             NaN   \n",
       "2  Revisa en el afiche qué tipo de papeles puedes...             NaN   \n",
       "3  Estimada Comunidad:   La Subdirección de Puebl...              NO   \n",
       "4  Postulaciones, labores y más información en:  ...             NaN   \n",
       "\n",
       "  sesgo_otro                                             target  \n",
       "0         NO  ['Estimada comunidad beauchefiana: ¿Tienes pap...  \n",
       "1        NaN  ['Desde hoy y hasta el 19 de diciembre puedes ...  \n",
       "2        NaN  ['Revisa en el afiche qué tipo de papeles pued...  \n",
       "3         NO  ['Estimada Comunidad:   La Subdirección de Pue...  \n",
       "4        NaN  ['Postulaciones, labores y más información en:...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 692, 7: 14, 6: 14, 8: 13, 5: 6, 2: 5, 4: 2, 3: 2})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "df['target'] = df['target'].apply(lambda text: ast.literal_eval(text))\n",
    "Counter([len(t) for t in df['target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "There are potentially many options for replacing a biased text. We will consider the highest similarity among all candidate options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = ['Se informa a la comunidad estudiantil que quienes NO asistan al proceso de captura fotográfica correspondiente a la retarjetización de la Tarjeta Nacional Estudiantil, quedarán sin esta nueva versión desde el próximo año.']\n",
    "predictions = ['Se informa a toda la comunidad estudiantil que las personas que NO asistan al proceso de captura fotográfica correspondiente a la retarjetización de la Tarjeta Nacional Estudiantil, no podrán obtener esta nueva versión desde el próximo año.' for _ in references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.9533587098121643], 'recall': [0.9690830707550049], 'f1': [0.9611566066741943], 'hashcode': 'bert-base-multilingual-cased_L9_no-idf_version=0.3.12(hug_trans=4.47.1)'}\n"
     ]
    }
   ],
   "source": [
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"bert-base-multilingual-cased\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the target either keeps the original text or corrects the bias in one of the several possible ways. We will separate the dataframe in a way that each one of them becomes a separate candidate for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('target', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bertscore.compute(predictions=df['output'], references=df['target'], model_type=\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['precision'] = results['precision']\n",
    "df['recall'] = results['recall']\n",
    "df['f1'] = results['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_best_scores(df, id_column, score_column):\n",
    "    \"\"\"\n",
    "    Reduces the dataframe to only the rows with the best score for each ID.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The original dataframe\n",
    "    - id_column (str): Name of the column containing unique IDs\n",
    "    - score_column (str): Name of the column containing the scores\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A filtered dataframe with the best score per ID\n",
    "    \"\"\"\n",
    "    # Find the maximum score for each ID_row\n",
    "    best_scores = df.groupby(id_column)[score_column].transform('max')\n",
    "    \n",
    "    # Filter the rows where the score matches the maximum score for each ID_row\n",
    "    filtered_df = df[df[score_column] == best_scores].copy(deep=True)\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = filter_best_scores(df, 'index', 'f1')\n",
    "len(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision \n",
      "\tmean: 0.9269657407533676\n",
      "\tstd: 0.14047231127303172\n",
      "\n",
      "recall \n",
      "\tmean: 0.9108940681273286\n",
      "\tstd: 0.16598013810897963\n",
      "\n",
      "f1 \n",
      "\tmean: 0.9183074262212304\n",
      "\tstd: 0.15385335547578152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for k in results.keys():\n",
    "    if not k == 'hashcode':\n",
    "        print(f'{k}',f'\\n\\tmean: {np.mean(df_results[k])}\\n\\tstd: {np.std(df_results[k])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtracting input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_input = bertscore.compute(\n",
    "    predictions=df_results['input'],\n",
    "    references=df_results['target'], model_type=\"bert-base-multilingual-cased\")\n",
    "df_results['precision_input'] = results_input['precision']\n",
    "df_results['recall_input'] = results_input['recall']\n",
    "df_results['f1_input'] = results_input['f1']\n",
    "\n",
    "df_results['precision_diff'] = df_results['precision'] - df_results['precision_input']\n",
    "df_results['recall_diff'] = df_results['recall'] - df_results['recall_input']\n",
    "df_results['f1_diff'] = df_results['f1'] - df_results['f1_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision \n",
      "\tmean (diff): -0.07182834588270136\n",
      "\tstd (diff): 0.14032722722045357\n",
      "\n",
      "recall \n",
      "\tmean (diff): -0.08700993031582092\n",
      "\tstd (diff): 0.1657036352223075\n",
      "\n",
      "f1 \n",
      "\tmean (diff): -0.08003377452253659\n",
      "\tstd (diff): 0.15364305560255223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in results.keys():\n",
    "    if not k == 'hashcode':\n",
    "        print(f'{k}',f\"\\n\\tmean (diff): {np.mean(df_results[k+'_diff'])}\\n\\tstd (diff): {np.std(df_results[k+'_diff'])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['f1_diff'] = df_results['f1_diff'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditions\n",
    "epsilon = 0.005\n",
    "\n",
    "conditions = [\n",
    "    df_results['f1_diff'] > epsilon,\n",
    "    df_results['f1_diff'] < -epsilon,\n",
    "    (df_results['f1_diff'] >= -epsilon) & (df_results['f1_diff'] <= epsilon)  # Values close to zero\n",
    "]\n",
    "\n",
    "# Assign values based on conditions\n",
    "choices = ['positive', 'negative', '0']\n",
    "df_results['f1_direction'] = np.select(conditions, choices, default='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Has bias\n",
       "Not-biasable    446\n",
       "NO              250\n",
       "YES              52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    (df_results['sesgo_pronombre'] == 'SI') | (df_results['sesgo_otro'] == 'SI'),\n",
    "    (df_results['sesgo_pronombre'] == 'NO') & (df_results['sesgo_otro'] == 'NO'),\n",
    "    df_results['sesgo_pronombre'].isna() & df_results['sesgo_otro'].isna()\n",
    "]\n",
    "\n",
    "# Assign values based on conditions\n",
    "choices = ['YES', 'NO', None]\n",
    "df_results['sesgo'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "df_results['Has bias'] = df_results['sesgo'].fillna('Not-biasable')\n",
    "df_results['Has bias'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency Matrix:\n",
      " f1_direction    0  negative  positive\n",
      "Has bias                             \n",
      "NO             98       152         0\n",
      "Not-biasable  330       116         0\n",
      "YES            23        24         5\n",
      "\n",
      "Percentage Matrix:\n",
      " f1_direction          0   negative  positive\n",
      "Has bias                                    \n",
      "NO            39.200000  60.800000  0.000000\n",
      "Not-biasable  73.991031  26.008969  0.000000\n",
      "YES           44.230769  46.153846  9.615385\n"
     ]
    }
   ],
   "source": [
    "# Frequency matrix\n",
    "freq_matrix = pd.crosstab(df_results['Has bias'], df_results['f1_direction'])\n",
    "\n",
    "# Percentage matrix\n",
    "percentage_matrix = freq_matrix.div(freq_matrix.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Display results\n",
    "print(\"Frequency Matrix:\\n\", freq_matrix)\n",
    "print(\"\\nPercentage Matrix:\\n\", percentage_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debiasing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
